{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5515fd8",
   "metadata": {},
   "source": [
    "# GPROF validation\n",
    "\n",
    "This notebook assesses the performance of the GPROF GMI retrieval against ground radar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "from gprof_nn.plotting import set_style\n",
    "set_style(latex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb519af",
   "metadata": {},
   "source": [
    "## Load collocated retrieval results\n",
    "\n",
    "To prepare the validation collocations for evaluation, the retrieval results must first be collocated with the reference/validation data using the ``gprof_nn combine_validation_data`` command. Following this valid validation samples can be extracted using the ``extract_results`` function provided by the ``gprof_nn.validation`` module.\n",
    "\n",
    "The collocated retrieval results are stored in separate files for every product and contain only pixels in which both MRMS, the product itself and GPM CMB have valid values. Samples from each year are combined into one file. We load all files into dictionaries ``results_db``, ``results_db_1``, ... ``results_db_3`` containing the samples from the database year + x. Additionally, we load collocation with the a priori database into ``results_db_ref``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "DATA_PATH = Path(\"/home/simonpf/data/gprof_nn/validation/gmi\")\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"combined\", \"gprof_nn_hr\"]\n",
    "results_db = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ae712",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_1 = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db_1.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d97ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_2 = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db_2.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_2[\"gprof_v5\"] = xr.load_dataset(\"/home/simonpf/data_3/gprof_nn/validation/gmi/results_gprof_v5_db_2.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b951123",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_3 = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db_3.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_ref = {group: xr.load_dataset(DATA_PATH / f\"results_{group}_db_ref.nc\") for group in groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e528a1f",
   "metadata": {},
   "source": [
    "## Observation frequencies\n",
    "\n",
    "This section displays the observation frequencies throught the validation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = np.arange(\"2018-10-01\", \"2022-11-01\", dtype=\"datetime64[M]\").astype(\"datetime64[s]\")\n",
    "times = []\n",
    "for results in [results_db, results_db_1, results_db_2, results_db_3]:\n",
    "    data = results[\"gprof_nn_3d\"]\n",
    "    times.append(data.time.data)\n",
    "    #with xr.open_dataset(results[\"gprof_nn_1d\"]) as data:\n",
    "times = np.concatenate(times)\n",
    "counts, _ = np.histogram(times, bins=time_bins)\n",
    "width = (time_bins[1:] - time_bins[:-1])\n",
    "x = time_bins[:-1] + 0.5 * (time_bins[1:] - time_bins[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(x, counts)\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938de68",
   "metadata": {},
   "source": [
    "## Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84940275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from gprof_nn.validation import NAMES\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gprof_nn.validation import calculate_scatter_plot, calculate_conditional_mean\n",
    "\n",
    "\n",
    "def make_scatter_plots(\n",
    "    no_frozen=True,\n",
    "    no_snow_sfc=True,\n",
    "    no_orographic=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Create scatter plots showing the conditional distribution of retrieved precipitation.\n",
    "    \n",
    "    Args:\n",
    "        no_frozen: Whether or not to exclude precipitation classified as frozen by MRMS\n",
    "        no_snow_sfc: Whether or not to exclude precipitation estimates of snow surfaces.\n",
    "        no_orographic: Whether or not to exclude mountain precipitation. \n",
    "        \n",
    "    Return:\n",
    "        A matplotlib figure containing the scatter plots.\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(20, 24))\n",
    "    gs = GridSpec(\n",
    "        8, 6,\n",
    "        width_ratios=[0.4]  + [1.0] * 5,\n",
    "        height_ratios=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.1],\n",
    "        hspace=0.15,\n",
    "        wspace=0.2\n",
    "    )\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, 1 + j]) for j in range(5)] \n",
    "        for i in range(6)\n",
    "    ] )\n",
    "    PERIODS = [\"A priori (2019)\", \"MRMS (2019)\", \"MRMS (2020)\", \"MRMS (2021)\", \"MRMS (2022)\"]\n",
    "\n",
    "    groups = NAMES.keys()\n",
    "    groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "\n",
    "    for i, group in enumerate(groups):\n",
    "\n",
    "        ax = f.add_subplot(gs[i, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, NAMES[group], rotation=90, ha=\"center\", va=\"center\")\n",
    "        ax.set_ylim([-2, 2])\n",
    "\n",
    "        for j, result in enumerate([results_db_ref, results_db, results_db_1, results_db_2, results_db_3]):\n",
    "\n",
    "            ax = axs[i, j]\n",
    "            if group == \"gprof_v5\" and j == 4:\n",
    "                ax.set_title(f\"{PERIODS[j]}\", loc=\"center\", pad=15)\n",
    "                ax.set_axis_off()\n",
    "                continue\n",
    "            x, y = calculate_scatter_plot(\n",
    "                result,\n",
    "                group,\n",
    "                no_frozen=no_frozen,\n",
    "                no_snow_sfc=no_snow_sfc,\n",
    "                no_orographic=no_orographic\n",
    "            )\n",
    "\n",
    "            #norm = LogNorm()\n",
    "            norm = Normalize(0, 0.1)\n",
    "            x = 0.5 * (x[1:] + x[:-1])\n",
    "            levels = np.logspace(-4, 0, 9)\n",
    "            mappable = ax.contourf(x, x, y.T, norm=LogNorm(1e-4, 1e0), levels=levels, extend=\"both\")\n",
    "\n",
    "            x, y = calculate_conditional_mean(\n",
    "                result,\n",
    "                group,\n",
    "                no_frozen=no_frozen,\n",
    "                no_snow_sfc=no_snow_sfc,\n",
    "                no_orographic=no_orographic\n",
    "            )\n",
    "            ax.plot(x, y, ls=\"--\", c=\"k\", label=\"Conditional mean\")\n",
    "\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.set_aspect(1.0)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"{PERIODS[j]}\", loc=\"center\", pad=15)\n",
    "            ax.set_xlim([1e-1, 1e2 + 1])\n",
    "            ax.set_ylim([1e-1, 1e2 + 1])\n",
    "\n",
    "            ax.plot(x, x, ls=\"--\", c=\"grey\")\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(r\"$P_\\text{Retrieved}$ [$\\si{\\milli \\meter \\per \\hour}$]\")\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                for m in ax.yaxis.get_majorticklines():\n",
    "                    m.set_visible(False)\n",
    "                for m in ax.yaxis.get_minorticklines():\n",
    "                    m.set_visible(False)\n",
    "                ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "            if i == 5:\n",
    "                if j == 0:\n",
    "                    ax.set_xlabel(r\"$P_\\text{A priori}$ [$\\si{\\milli \\meter \\per \\hour}$]\")\n",
    "                else:\n",
    "                    ax.set_xlabel(r\"$P_\\text{MRMS}$ [$\\si{\\milli \\meter \\per \\hour}$]\")\n",
    "                    \n",
    "            else:\n",
    "                ax.set_xticklabels([])\n",
    "                for m in ax.xaxis.get_majorticklines():\n",
    "                    m.set_visible(False)\n",
    "                for m in ax.xaxis.get_minorticklines():\n",
    "                    m.set_visible(False)\n",
    "                ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    # Colorbars\n",
    "    ax = f.add_subplot(gs[-1, 1:])\n",
    "    cb = plt.colorbar(mappable, label=r\"$p(P_\\text{Retrieved}|P_\\text{A priori / MRMS})$ [\\si{(\\milli \\meter \\, \\hour^{-1})^{-1}}]\", cax=ax, orientation=\"horizontal\")\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f494a3f",
   "metadata": {},
   "source": [
    "#### No snow surfaces, no mountains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_scatter_plots(no_frozen=True, no_snow_sfc=True, no_orographic=True);\n",
    "fig.savefig(\"../../plots/validation/scatter.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_scatter_plots(no_frozen=True, no_snow_sfc=True, no_orographic=True);\n",
    "fig.savefig(\"../../plots/validation/scatter.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7953cb",
   "metadata": {},
   "source": [
    "#### All samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e87b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_scatter_plots(no_frozen=False, no_snow_sfc=False, no_orographic=False);\n",
    "fig.savefig(\"../../plots/validation/scatter_all.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6518d",
   "metadata": {},
   "source": [
    "### Error metrics\n",
    "\n",
    "This code calculates and displayes the quantitative error metrics for every product and year and displays them as bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf069512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gprof_nn.validation import calculate_error_metrics\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\"]\n",
    "\n",
    "def calculate_stats(\n",
    "    no_frozen: bool,\n",
    "    no_snow_sfc: bool,\n",
    "    no_orographic: bool = True,\n",
    "    no_ocean: bool = True\n",
    "):\n",
    "    stats_db = calculate_error_metrics(\n",
    "        results_db_ref,\n",
    "        groups + [\"combined\"],\n",
    "        no_frozen=no_frozen,\n",
    "        no_snow_sfc=no_snow_sfc,\n",
    "        no_orographic=no_orographic,\n",
    "        no_ocean=no_ocean,\n",
    "    )\n",
    "    stats_db_0 = calculate_error_metrics(\n",
    "        results_db,\n",
    "        groups + [\"combined\"],\n",
    "        no_frozen=no_frozen,\n",
    "        no_snow_sfc=no_snow_sfc,\n",
    "        no_orographic=no_orographic,\n",
    "        no_ocean=no_ocean,\n",
    "    )\n",
    "    stats_db_1 = calculate_error_metrics(\n",
    "        results_db_1,\n",
    "        groups + [\"combined\"],\n",
    "        no_frozen=no_frozen,\n",
    "        no_snow_sfc=no_snow_sfc,\n",
    "        no_orographic=no_orographic,\n",
    "        no_ocean=no_ocean,\n",
    "    )\n",
    "    stats_db_2 = calculate_error_metrics(\n",
    "        results_db_2,\n",
    "        groups + [\"combined\"],\n",
    "        no_frozen=no_frozen,\n",
    "        no_snow_sfc=no_snow_sfc,\n",
    "        no_orographic=no_orographic,\n",
    "        no_ocean=no_ocean,\n",
    "    )\n",
    "    stats_db_3 = calculate_error_metrics(\n",
    "        results_db_3,\n",
    "        groups[1:] + [\"combined\"],\n",
    "        no_frozen=no_frozen,\n",
    "        no_snow_sfc=no_snow_sfc,\n",
    "        no_orographic=no_orographic,\n",
    "        no_ocean=no_ocean,\n",
    "    )\n",
    "    \n",
    "    stats_db[\"Time period\"] = \"A Priori (2019)\"\n",
    "    stats_db = stats_db.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "    stats_db_0[\"Time period\"] = \"MRMS (2019)\"\n",
    "    stats_db_0 = stats_db_0.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "    stats_db_1[\"Time period\"] = \"MRMS (2020)\"\n",
    "    stats_db_1 = stats_db_1.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "    stats_db_2[\"Time period\"] = \"MRMS (2021)\"\n",
    "    stats_db_2 = stats_db_2.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "    stats_db_3[\"Time period\"] = \"MRMS (2022)\"\n",
    "    stats_db_3 = stats_db_3.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "    \n",
    "    stats = pd.concat([\n",
    "        stats_db,\n",
    "        stats_db_0,\n",
    "        stats_db_1,\n",
    "        stats_db_2,\n",
    "        stats_db_3\n",
    "    ])\n",
    "    \n",
    "    return stats\n",
    "\n",
    "stats = calculate_stats(no_frozen=True, no_snow_sfc=True, no_orographic=True)\n",
    "stats_all = calculate_stats(no_frozen=False, no_snow_sfc=False, no_orographic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[stats[\"Time period\"] == \"MRMS (2020)\"].to_csv(\"gmi_2020_conus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fe398",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[stats[\"Time period\"] == \"MRMS (2020)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from gprof_nn.validation import get_colors, NAMES\n",
    "\n",
    "def plot_stats(stats):\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    gs = GridSpec(3, 3, height_ratios= [1.0] * 2 + [0.5], wspace=0.3, hspace=0.2)\n",
    "    colors = get_colors()\n",
    "\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j]) for j in range(3)]\n",
    "        for i in range(2)\n",
    "    ])\n",
    "\n",
    "    y_lims = {\n",
    "        \"Bias\": [-15, 15]\n",
    "    }\n",
    "\n",
    "    y_labels = {\n",
    "        \"Bias\": \"Bias [$\\si{\\percent}$]\",\n",
    "        \"MAE\": \"MAE [$\\si{\\milli \\meter \\per \\hour}$]\",\n",
    "        \"MSE\": \"MSE [$(\\si{\\milli \\meter \\per \\hour})^2$]\",\n",
    "        \"SMAPE\": \"SMAPE$_{0.1}$ [$\\si{\\percent}$]\",\n",
    "    }\n",
    "\n",
    "    bar_palette = list(colors.values())\n",
    "\n",
    "    metrics = [\"Bias\", \"MAE\", \"MSE\", \"Correlation coeff.\", \"SMAPE\"]\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axs[i // 3, i % 3]\n",
    "        g = sns.barplot(\n",
    "            x=\"Time period\",\n",
    "            y=metric,\n",
    "            hue=\"Algorithm\",\n",
    "            data=stats,\n",
    "            ax=ax,\n",
    "            saturation=1.0,\n",
    "            palette=bar_palette\n",
    "        )\n",
    "        g.legend_.set_visible(False)\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            ax.axhline(y=0, ls=\"--\", c=\"k\")\n",
    "\n",
    "        if i // 3 == 0 and i % 3 < 2:\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_xlabel(None)\n",
    "        else:\n",
    "            for l in ax.get_xticklabels():\n",
    "                l.set_rotation(45)\n",
    "\n",
    "        if metric in y_labels:\n",
    "            ax.set_ylabel(y_labels[metric])\n",
    "\n",
    "        if metric in y_lims:\n",
    "            ax.set_ylim(y_lims[metric])\n",
    "\n",
    "        #ax.set_title(f\"({chr(ord('a') + i)})\")\n",
    "\n",
    "    axs[-1, -1].set_axis_off()\n",
    "\n",
    "    lax = f.add_subplot(gs[-1, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(*ax.get_legend_handles_labels(), ncol=6, loc=\"lower center\")\n",
    "\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84236515",
   "metadata": {},
   "source": [
    "#### No frozen, no snow surfaces, no orographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_stats(stats)\n",
    "f.savefig(\"../../plots/validation/metrics.pdf\", bbox_inches=\"tight\")\n",
    "f.savefig(\"../../plots/validation/metrics.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827724e",
   "metadata": {},
   "source": [
    "#### All samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49308d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_stats(stats_all)\n",
    "f.savefig(\"../../plots/validation/metrics_all.pdf\", bbox_inches=\"tight\")\n",
    "f.savefig(\"../../plots/validation/metrics_all.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3532cb5",
   "metadata": {},
   "source": [
    "## Error maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "cmap = sns.color_palette(\"vlag_r\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.validation import gridded_stats, CONUS\n",
    "\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "results = {\n",
    "    \"A priori (2019)\": results_db_ref,\n",
    "    \"MRMS (2019)\": results_db,\n",
    "    \"MRMS (2020)\": results_db_1,\n",
    "    \"MRMS (2021)\": results_db_2,\n",
    "    \"MRMS (2022)\": results_db_3\n",
    "}\n",
    "bins = (np.arange(CONUS[0], CONUS[2], 5.0), np.arange(CONUS[1], CONUS[3], 5.0))\n",
    "\n",
    "def calculate_spatial_stats(\n",
    "    no_frozen: bool,\n",
    "    no_snow_sfc: bool,\n",
    "    no_ocean: bool = True,\n",
    "    no_orographic: bool = True\n",
    "):\n",
    "    corrs = {}\n",
    "    biases = {}\n",
    "\n",
    "    for group in groups:\n",
    "        for name, data in results.items():\n",
    "\n",
    "            bias, mae, mse, corr = gridded_stats(\n",
    "                data[group],\n",
    "                bins,\n",
    "                min_samples=1000,\n",
    "                no_ocean=no_ocean,\n",
    "                no_orographic=no_orographic,\n",
    "                no_frozen=no_frozen,\n",
    "                no_snow_sfc=no_snow_sfc\n",
    "            )\n",
    "\n",
    "            biases.setdefault(group, {})[name] = bias\n",
    "            corrs.setdefault(group, {})[name] = corr\n",
    "            \n",
    "    return biases, corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases, corrs = calculate_spatial_stats(no_frozen=True, no_snow_sfc=True, no_orographic=True, no_ocean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_all, corrs_all = calculate_spatial_stats(no_frozen=False, no_snow_sfc=False, no_orographic=False, no_ocean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_style(latex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ba12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.data.validation import CONUS\n",
    "from gprof_nn.validation import REGIONS, gridded_stats\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import Normalize\n",
    "from gprof_nn.validation import NAMES\n",
    "\n",
    "\n",
    "def make_bias_plots(biases):\n",
    "    \"\"\"\n",
    "    Plots maps of spatial biases for multiple retrievals and time periods.\n",
    "    \n",
    "    Args:\n",
    "        biases: Nested dict mapping retrieval names and period names to maps of\n",
    "             biases.\n",
    "             \n",
    "    Rerturn:\n",
    "        A matplotlib.Figure containing the rendered bias maps.\n",
    "    \"\"\"\n",
    "    selection = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "    M = len(selection)\n",
    "    N = 5\n",
    "    f = plt.figure(figsize=(N * 4.4 + 1, M * 2.4))\n",
    "    gs = GridSpec(M + 1, N + 1, width_ratios= [0.1] + [1.0] * N, height_ratios=[1.0] * M + [0.1], hspace=0.05, wspace=0.05)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j + 1], projection=ccrs.PlateCarree()) for j in range(N)]\n",
    "        for i in range(M)\n",
    "    ])\n",
    "\n",
    "    periods = [\"A priori (2019)\", \"MRMS (2019)\", \"MRMS (2020)\", \"MRMS (2021)\", \"MRMS (2022)\"]\n",
    "    bins = (np.arange(CONUS[0], CONUS[2], 5.0), np.arange(CONUS[1], CONUS[3], 5.0))\n",
    "    c_lon = 0.5 * (bins[0][1:] + bins[0][:-1])\n",
    "    c_lat = 0.5 * (bins[1][1:] + bins[1][:-1])\n",
    "    levels = np.linspace(-0.055, 0.055, 12)\n",
    "\n",
    "    # Bias\n",
    "    norm = Normalize(-0.025, 0.025)\n",
    "    for i, group in enumerate(selection):\n",
    "        ax = f.add_subplot(gs[i, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, NAMES[group], rotation=90, va=\"center\", ha=\"center\")\n",
    "        ax.set_ylim([-2, 2])\n",
    "\n",
    "        for j, period in enumerate(periods):\n",
    "\n",
    "            ax = axs[i, j]\n",
    "            \n",
    "            # Skip GPROF V5 for year 2022\n",
    "            if (i == 0) and (j == 4):\n",
    "                ax.set_title(periods[4])\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            bias = biases[group][period]\n",
    "            m = ax.pcolormesh(\n",
    "                bins[0],\n",
    "                bins[1],\n",
    "                bias.T,\n",
    "                vmin=-0.05,\n",
    "                vmax=0.05,\n",
    "                cmap=\"coolwarm_r\",\n",
    "                rasterized=True\n",
    "            )\n",
    "\n",
    "            ax.coastlines()\n",
    "            ax.set_xlim([CONUS[0] + 1, CONUS[2] - 1])\n",
    "            ax.set_ylim([CONUS[1] + 1, CONUS[3] - 1])\n",
    "            if i == 0:\n",
    "                ax.set_title(periods[j])\n",
    "\n",
    "    ax = f.add_subplot(gs[-1, 1:])\n",
    "    plt.colorbar(m, label=r\"$\\overline{P_\\text{Retrieved} - P_\\text{A priori/MRMS}}$ [$\\si{\\milli \\meter \\per \\hour}$]\", cax=ax, orientation=\"horizontal\")\n",
    "    plt.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c19c47",
   "metadata": {},
   "source": [
    "#### No snow, no snow surfaces, no orographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_bias_plots(biases);\n",
    "fig.savefig(\"../../plots/validation/bias_maps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf000a3c",
   "metadata": {},
   "source": [
    "#### All samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e95e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_bias_plots(biases_all);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462b881",
   "metadata": {},
   "source": [
    "## Corrected biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.data.validation import CONUS\n",
    "from gprof_nn.validation import REGIONS, gridded_stats\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import Normalize\n",
    "from gprof_nn.validation import NAMES\n",
    "\n",
    "def make_corrected_bias_plots(biases):\n",
    "    \"\"\"\n",
    "    Plots maps of spatial biases corrected for GPM CMB retrievals.\n",
    "    \n",
    "    Args:\n",
    "        biases: Nested dict mapping retrieval names and period names to maps of\n",
    "             biases.\n",
    "             \n",
    "    Rerturn:\n",
    "        A matplotlib.Figure containing the rendered bias maps.\n",
    "    \"\"\"\n",
    "    selection = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\"]\n",
    "    M = len(selection)\n",
    "    N = 5\n",
    "    f = plt.figure(figsize=(N * 4.4 + 1, M * 2.4))\n",
    "    gs = GridSpec(M + 1, N + 1, width_ratios= [0.1] + [1.0] * N, height_ratios=[1.0] * M + [0.1], hspace=0.05, wspace=0.05)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j + 1], projection=ccrs.PlateCarree()) for j in range(N)]\n",
    "        for i in range(M)\n",
    "    ])\n",
    "\n",
    "    periods = [\"A priori (2019)\", \"MRMS (2019)\", \"MRMS (2020)\", \"MRMS (2021)\", \"MRMS (2022)\"]\n",
    "    bins = (np.arange(CONUS[0], CONUS[2], 5.0), np.arange(CONUS[1], CONUS[3], 5.0))\n",
    "    c_lon = 0.5 * (bins[0][1:] + bins[0][:-1])\n",
    "    c_lat = 0.5 * (bins[1][1:] + bins[1][:-1])\n",
    "    levels = np.linspace(-0.055, 0.055, 12)\n",
    "\n",
    "    # Bias\n",
    "    norm = Normalize(-0.025, 0.025)\n",
    "    for i, group in enumerate(selection):\n",
    "        ax = f.add_subplot(gs[i, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, NAMES[group], rotation=90, va=\"center\", ha=\"center\")\n",
    "        ax.set_ylim([-2, 2])\n",
    "\n",
    "        for j, period in enumerate(periods):\n",
    "\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            # Skip GPROF V5 for year 2022\n",
    "            if (i == 0) and (j == 4):\n",
    "                ax.set_title(periods[4])\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            bias = biases[group][period]\n",
    "            bias -= biases[\"combined\"][period]\n",
    "\n",
    "            m = ax.pcolormesh(bins[0], bins[1],  bias.T, vmin=-0.05, vmax=0.05, cmap=\"coolwarm_r\", rasterized=True)\n",
    "\n",
    "            ax.coastlines()\n",
    "            ax.set_xlim([CONUS[0] + 1, CONUS[2] - 1])\n",
    "            ax.set_ylim([CONUS[1] + 1, CONUS[3] - 1])\n",
    "            if i == 0:\n",
    "                ax.set_title(periods[j])\n",
    "\n",
    "    ax = f.add_subplot(gs[-1, 1:])\n",
    "    plt.colorbar(m, label=r\"$\\overline{P_\\text{Retrieved} - P_\\text{A priori/MRMS}}$ [$\\si{\\milli \\meter \\per \\hour}$]\", cax=ax, orientation=\"horizontal\")\n",
    "    plt.tight_layout()\n",
    "    return f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_corrected_bias_plots(biases);\n",
    "f.savefig(\"../../plots/validation/bias_maps_corrected.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780fdea",
   "metadata": {},
   "source": [
    "## Correlation coefficient maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59129b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.data.validation import CONUS\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import Normalize, BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "from gprof_nn.validation import NAMES\n",
    "\n",
    "\n",
    "def make_correlation_plots(corrs):\n",
    "    selection = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "    M = len(selection)\n",
    "    N = 5\n",
    "    f = plt.figure(figsize=(N * 4.4 + 1, M * 2.4))\n",
    "    gs = GridSpec(M + 1, N + 1, width_ratios= [0.1] + [1.0] * N, height_ratios=[1.0] * M + [0.1], hspace=0.05, wspace=0.05)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j + 1], projection=ccrs.PlateCarree()) for j in range(N)]\n",
    "        for i in range(M)\n",
    "    ])\n",
    "\n",
    "    periods = [\"A priori (2019)\", \"MRMS (2019)\", \"MRMS (2020)\", \"MRMS (2021)\", \"MRMS (2022)\"]\n",
    "    bins = (np.arange(CONUS[0], CONUS[2], 5.0), np.arange(CONUS[1], CONUS[3], 5.0))\n",
    "    c_lon = 0.5 * (bins[0][1:] + bins[0][:-1])\n",
    "    c_lat = 0.5 * (bins[1][1:] + bins[1][:-1])\n",
    "    levels = np.linspace(0.0, 1.0, 21)\n",
    "    cmap = get_cmap(\"magma\", len(levels))\n",
    "    norm = BoundaryNorm(levels, len(levels))\n",
    "\n",
    "    for i, group in enumerate(selection):\n",
    "\n",
    "        ax = f.add_subplot(gs[i, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, NAMES[group], rotation=90, va=\"center\", ha=\"center\")\n",
    "        ax.set_ylim([-2, 2])\n",
    "\n",
    "        for j, period in enumerate(periods):\n",
    "            ax = axs[i, j]\n",
    "            #ax.background_img(\"ne_gray\")\n",
    "\n",
    "            # Skip GPROF V5 for year 2022\n",
    "            if (i == 0) and (j == 4):\n",
    "                ax.set_title(periods[4])\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            corr = corrs[group][period]\n",
    "            m = ax.pcolormesh(bins[0], bins[1],  corr.T, norm=norm, cmap=cmap, rasterized=True)\n",
    "\n",
    "            ax.coastlines(color=\"grey\")\n",
    "            ax.set_xlim([CONUS[0], CONUS[2]])\n",
    "            ax.set_ylim([CONUS[1], CONUS[3]])\n",
    "            if i == 0:\n",
    "                ax.set_title(periods[j])\n",
    "\n",
    "    ax = f.add_subplot(gs[-1, 1:])\n",
    "    plt.colorbar(m, label=\"Correlation coeff.\", cax=ax, orientation=\"horizontal\")\n",
    "    plt.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4144757",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = make_correlation_plots(corrs);\n",
    "f.savefig(\"../../plots/validation/correlation_maps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495551c",
   "metadata": {},
   "source": [
    "## Precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5927a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.validation import get_colors\n",
    "COLORS = get_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.data.validation import CONUS\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import Normalize\n",
    "from gprof_nn.validation import NAMES, calculate_pr_curve, get_colors\n",
    "\n",
    "def plot_pr_curves(\n",
    "    no_frozen: bool,\n",
    "    no_snow_sfc: bool,\n",
    "    no_ocean: bool = True,\n",
    "    no_orographic: bool = True,\n",
    "    fpa: bool = False\n",
    "):\n",
    "    selection = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\"]\n",
    "    colors = get_colors()\n",
    "\n",
    "    N = 5\n",
    "    f = plt.figure(figsize=(3 * 5, 2 * 5))\n",
    "    gs = GridSpec(2, 3, hspace=0.2, wspace=0.20)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[j // 3, j % 3]) for j in range(N)]\n",
    "    ])\n",
    "\n",
    "    periods = [\"A priori (2019)\", \"MRMS (2019)\", \"MRMS (2020)\", \"MRMS (2021)\", \"MRMS (2022)\"]\n",
    "    for i, results in enumerate([results_db_ref, results_db, results_db_1, results_db_2, results_db_3]):\n",
    "\n",
    "        if i < 4:\n",
    "            handles = []\n",
    "\n",
    "        for retrieval in selection:\n",
    "            \n",
    "            if i == 4 and retrieval == \"gprof_v5\":\n",
    "                continue\n",
    "\n",
    "            data = results[retrieval]\n",
    "            precision, recall, thresholds = calculate_pr_curve(\n",
    "                data,\n",
    "                fpa=fpa,\n",
    "                no_ocean=no_ocean,\n",
    "                no_orographic=no_orographic,\n",
    "                no_frozen=no_frozen,\n",
    "                no_snow_sfc=no_snow_sfc\n",
    "            )\n",
    "\n",
    "            ax = axs[0, i] \n",
    "            period = periods[i]\n",
    "\n",
    "            handles_i = ax.plot(recall, precision, c=colors[retrieval], label=NAMES[retrieval])\n",
    "            if i < 4:\n",
    "                handles += handles_i\n",
    "\n",
    "            if (i < 2):\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_xlabel(\"\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"Recall\")\n",
    "\n",
    "            ax.set_xlim([0, 1])\n",
    "            ax.set_ylim([0, 1])\n",
    "            if i % 3 == 0:\n",
    "                ax.set_ylabel(\"Precision\")\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "\n",
    "            ax.set_title(f\"({chr(ord('a') + i)}) {period}\", loc=\"left\", pad=15)\n",
    "\n",
    "    ax = f.add_subplot(gs[1, -1])\n",
    "    ax.set_axis_off()\n",
    "    ax.legend(handles=handles, loc=\"center\")\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_pr_curves(no_frozen=True, no_snow_sfc=True, no_ocean=True, no_orographic=True);\n",
    "f.savefig(\"../../plots/validation/pr_curves.pdf\", bbox_inches=\"tight\")\n",
    "f.savefig(\"../../plots/validation/pr_curves.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10167",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_pr_curves(no_frozen=True, no_snow_sfc=False, no_ocean=False, no_orographic=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e8d20",
   "metadata": {},
   "source": [
    "# Regional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33599c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/home/simonpf/data_3/gmi\")\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "results_db_ref_kwaj = {group: xr.load_dataset(DATA_PATH / f\"../kwaj_gmi/results_{group}_db_ref.nc\") for group in groups}\n",
    "results_db_kwaj = {group: xr.load_dataset(DATA_PATH / f\"../kwaj_gmi/results_{group}_db.nc\") for group in groups}\n",
    "results_db_1_kwaj = {group: xr.load_dataset(DATA_PATH / f\"../kwaj_gmi/results_{group}_db_1.nc\") for group in groups}\n",
    "results_db_2_kwaj = {group: xr.load_dataset(DATA_PATH / f\"../kwaj_gmi/results_{group}_db_2.nc\") for group in groups}\n",
    "results_db_3_kwaj = {group: xr.load_dataset(DATA_PATH / f\"../kwaj_gmi/results_{group}_db_3.nc\") for group in groups[1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8296300",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_db_ref_all = {}\n",
    "results_db_all = {}\n",
    "results_db_1_all = {}\n",
    "results_db_2_all = {}\n",
    "results_db_3_all = {}\n",
    "\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    " \n",
    "for k in groups:\n",
    "    data = results_db_ref[k].drop_vars(\"airmass_type\")\n",
    "    data_kwaj = results_db_ref_kwaj[k].copy()\n",
    "    sp = data_kwaj.surface_precip_avg.data\n",
    "    data_kwaj[\"rqi\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data_kwaj[\"mask\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data[\"range\"] = ((\"samples\"), np.nan * np.ones_like(data.surface_precip.data))\n",
    "    results_db_ref_all[k] = xr.concat([data, data_kwaj], dim=\"samples\")\n",
    "del results_db_ref\n",
    "\n",
    "for k in groups:\n",
    "    data = results_db[k]\n",
    "    data_kwaj = results_db_kwaj[k].copy()\n",
    "    sp = data_kwaj.surface_precip_avg.data\n",
    "    data_kwaj[\"rqi\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data_kwaj[\"mask\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data[\"range\"] = ((\"samples\"), np.nan * np.ones_like(data.surface_precip.data))\n",
    "    results_db_all[k] = xr.concat([data, data_kwaj], dim=\"samples\")\n",
    "del results_db\n",
    "    \n",
    "for k in groups:\n",
    "    data = results_db_1[k]\n",
    "    data_kwaj = results_db_1_kwaj[k].copy()\n",
    "    sp = data_kwaj.surface_precip_avg.data\n",
    "    data_kwaj[\"rqi\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data_kwaj[\"mask\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data[\"range\"] = ((\"samples\"), np.nan * np.ones_like(data.surface_precip.data))\n",
    "    results_db_1_all[k] = xr.concat([data, data_kwaj], dim=\"samples\")\n",
    "del results_db_1\n",
    "    \n",
    "for k in groups:\n",
    "    data = results_db_2[k]\n",
    "    data_kwaj = results_db_2_kwaj[k].copy()\n",
    "    sp = data_kwaj.surface_precip_avg.data\n",
    "    data_kwaj[\"rqi\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data_kwaj[\"mask\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data[\"range\"] = ((\"samples\"), np.nan * np.ones_like(data.surface_precip.data))\n",
    "    results_db_2_all[k] = xr.concat([data, data_kwaj], dim=\"samples\")\n",
    "del results_db_2\n",
    "    \n",
    "for k in groups[1:]:\n",
    "    data = results_db_3[k]\n",
    "    data_kwaj = results_db_3_kwaj[k].copy()\n",
    "    sp = data_kwaj.surface_precip_avg.data\n",
    "    data_kwaj[\"rqi\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data_kwaj[\"mask\"] = ((\"samples\"), 999.0 * np.ones_like(sp))\n",
    "    data[\"range\"] = ((\"samples\"), np.nan * np.ones_like(data.surface_precip.data))\n",
    "    results_db_3_all[k] = xr.concat([data, data_kwaj], dim=\"samples\")\n",
    "del results_db_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47932dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.validation import REGIONS, calculate_error_metrics\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_region_metrics(\n",
    "    no_frozen: bool,\n",
    "    no_snow_sfc: bool,\n",
    "    no_orographic: bool = True,\n",
    "    no_ocean: bool = True\n",
    "):\n",
    "    region_metrics = []\n",
    "    ranges = [None,] * 5 + [80e3]\n",
    "    for region, rng in zip(REGIONS, ranges):\n",
    "        print(region)\n",
    "        no_ocean = region != \"KWAJ\"\n",
    "        no_ocean = False\n",
    "        metrics = calculate_error_metrics(\n",
    "            results_db_ref_all,\n",
    "            groups,\n",
    "            region=region,\n",
    "            ranges=rng,\n",
    "            no_orographic=no_orographic,\n",
    "            no_ocean=no_ocean,\n",
    "            no_frozen=no_frozen\n",
    "        ).reset_index()\n",
    "        metrics = metrics.rename(columns={\"index\": \"Algorithm\"})\n",
    "        metrics[\"Region\"] = region\n",
    "        metrics[\"Time period\"] = \"A priori (2019)\"\n",
    "\n",
    "        region_metrics.append(metrics)\n",
    "        metrics = calculate_error_metrics(\n",
    "            results_db_all,\n",
    "            groups,\n",
    "            region=region,\n",
    "            ranges=rng,\n",
    "            no_orographic=no_orographic,\n",
    "            no_ocean=no_ocean,\n",
    "            no_frozen=no_frozen\n",
    "        ).reset_index()\n",
    "        metrics = metrics.rename(columns={\"index\": \"Algorithm\"})\n",
    "        metrics[\"Region\"] = region\n",
    "        metrics[\"Time period\"] = \"MRMS (2019)\"\n",
    "        region_metrics.append(metrics)\n",
    "\n",
    "        metrics = calculate_error_metrics(\n",
    "            results_db_1_all,\n",
    "            groups,\n",
    "            region=region,\n",
    "            ranges=rng,\n",
    "            no_orographic=no_orographic,\n",
    "            no_ocean=no_ocean,\n",
    "            no_frozen=no_frozen\n",
    "        ).reset_index()\n",
    "        metrics = metrics.rename(columns={\"index\": \"Algorithm\"})\n",
    "        metrics[\"Region\"] = region\n",
    "        metrics[\"Time period\"] = \"MRMS (2020)\"\n",
    "        region_metrics.append(metrics)\n",
    "\n",
    "        metrics = calculate_error_metrics(\n",
    "            results_db_2_all,\n",
    "            groups,\n",
    "            region=region,\n",
    "            ranges=rng,\n",
    "            no_orographic=no_orographic,\n",
    "            no_ocean=no_ocean,\n",
    "            no_frozen=no_frozen\n",
    "        ).reset_index()\n",
    "        metrics = metrics.rename(columns={\"index\": \"Algorithm\"})\n",
    "        metrics[\"Region\"] = region\n",
    "        metrics[\"Time period\"] = \"MRMS (2021)\"\n",
    "        region_metrics.append(metrics)\n",
    "\n",
    "        metrics = calculate_error_metrics(\n",
    "            results_db_3_all,\n",
    "            groups[1:],\n",
    "            region=region,\n",
    "            ranges=rng,\n",
    "            no_orographic=no_orographic,\n",
    "            no_ocean=no_ocean,\n",
    "            no_frozen=no_frozen\n",
    "        ).reset_index()\n",
    "        metrics = metrics.rename(columns={\"index\": \"Algorithm\"})\n",
    "        metrics[\"Region\"] = region\n",
    "        metrics[\"Time period\"] = \"MRMS (2022)\"\n",
    "        region_metrics.append(metrics)\n",
    "        \n",
    "    region_metrics = pd.concat(region_metrics)\n",
    "    return region_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_metrics = calculate_region_metrics(no_frozen=True, no_snow_sfc=True, no_orographic=True)\n",
    "region_metrics_all = calculate_region_metrics(no_frozen=False, no_snow_sfc=False, no_orographic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afdb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.validation import calculate_precip_contribution, PRECIP_TYPES\n",
    "import pandas as pd\n",
    "\n",
    "precip_names = list(PRECIP_TYPES.keys())\n",
    "\n",
    "\n",
    "def calculate_precip_contribs(\n",
    "    no_frozen,\n",
    "    no_snow_sfc,\n",
    "    no_ocean=False,\n",
    "    no_orographic=True\n",
    "):\n",
    "    contribs = []\n",
    "    precip_types = []\n",
    "    regions = []\n",
    "    periods = []\n",
    "    results = {\n",
    "        \"A priori (2019)\": results_db_all[\"gprof_nn_1d\"],\n",
    "        \"Ground radar (2019)\": results_db_all[\"gprof_nn_1d\"],\n",
    "        \"Ground radar (2020)\": results_db_1_all[\"gprof_nn_1d\"],\n",
    "        \"Ground radar (2021)\": results_db_2_all[\"gprof_nn_1d\"],\n",
    "        \"Ground radar (2022)\": results_db_3_all[\"gprof_nn_1d\"],\n",
    "    }\n",
    "\n",
    "    for period, result in results.items():\n",
    "        for region in REGIONS.keys():\n",
    "            contribs.append(calculate_precip_contribution(result, region=region, absolute=True))\n",
    "            regions.append(region)\n",
    "            precip_types.append(\"Total\")\n",
    "            periods.append(period)\n",
    "\n",
    "            for precip_type in [\"Stratiform\", \"Convective\", \"Snow\"]:\n",
    "                if \"mask\" in result:\n",
    "                    contribs.append(\n",
    "                        calculate_precip_contribution(\n",
    "                            result,\n",
    "                            precip_type,\n",
    "                            region=region,\n",
    "                            absolute=True,\n",
    "                            no_frozen=no_frozen,\n",
    "                            no_snow_sfc=no_snow_sfc,\n",
    "                            no_ocean=no_ocean,\n",
    "                            no_orographic=no_orographic\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    contribs.append = 0.0\n",
    "                regions.append(region)\n",
    "                precip_types.append(precip_type)\n",
    "                periods.append(period)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Region\": regions,\n",
    "        \"Contribution\": contribs,\n",
    "        \"Precip type\": precip_types,\n",
    "        \"Period\": periods\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_contribs = calculate_precip_contribs(no_frozen=True, no_snow_sfc=True, no_orographic=True)\n",
    "precip_contribs_all = calculate_precip_contribs(no_frozen=False, no_snow_sfc=False, no_orographic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80094d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_contribs = precip_contribs[precip_contribs[\"Precip type\"] != \"Snow\"]\n",
    "precip_contribs_all = precip_contribs_all[precip_contribs_all[\"Precip type\"] != \"Snow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647286ae",
   "metadata": {},
   "source": [
    "### Regional statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from gprof_nn.validation import get_colors\n",
    "set_style(latex=True)\n",
    "COLORS = get_colors()\n",
    "bar_palette = list(COLORS.values())\n",
    "colors = sns.color_palette(\"Greys\", 5)[1:]\n",
    "\n",
    "def plot_regional_metrics(\n",
    "    region_metrics,\n",
    "    precip_contribs\n",
    "):\n",
    "    f = plt.figure(figsize=(20, 20))\n",
    "    gs = GridSpec(8, 6, height_ratios= [1.0, 0.2] + [1.0] * 5 + [1.5], hspace=0.2, wspace=0.05)\n",
    "\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[2 + i, j]) for j in range(6)]\n",
    "        for i in range(5)\n",
    "    ])\n",
    "\n",
    "    y_lims = {\n",
    "        \"Bias\": [-35, 35],\n",
    "        \"MAE\": [0, 0.4],\n",
    "        \"MSE\": [0, 4.0],\n",
    "        \"Correlation\": [0, 1.0],\n",
    "        \"SMAPE\": [0, 120],\n",
    "    }\n",
    "\n",
    "    y_labels = {\n",
    "        \"Bias\": \"Bias [$\\si{\\percent}$]\",\n",
    "        \"MAE\": \"MAE [$\\si{\\milli \\meter \\per \\hour}$]\",\n",
    "        \"MSE\": \"MSE [$(\\si{\\milli \\meter \\per \\hour})^2$]\",\n",
    "        \"SMAPE\": \"SMAPE$_{0.1}$ [$\\si{\\percent}$]\",\n",
    "    }\n",
    "\n",
    "    groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "    metrics = [\"Bias\", \"MAE\", \"MSE\", \"Correlation coeff.\", \"SMAPE\"]\n",
    "\n",
    "    for j, region in enumerate(REGIONS):\n",
    "        ax = f.add_subplot(gs[0, j])\n",
    "        m = precip_contribs[precip_contribs[\"Region\"] == region]\n",
    "        g = sns.barplot(x=\"Period\", y=\"Contribution\", hue=\"Precip type\", data=m,\n",
    "                        ax=ax, saturation=0.9, palette=colors)\n",
    "        g.legend_.set_visible(False)\n",
    "        ax.set_title(region)\n",
    "\n",
    "        ax.set_ylim(0, 0.25)\n",
    "        if j > 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticklabels([])\n",
    "        else:\n",
    "            ax.set_ylabel(r\"Mean precip [$\\si{\\milli \\meter \\per \\hour}$]\")\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "    lax = f.add_subplot(gs[1, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(*ax.get_legend_handles_labels(), ncol=8, loc=\"center\")\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, region in enumerate(REGIONS):\n",
    "            ax = axs[i, j]\n",
    "            m = region_metrics[region_metrics[\"Region\"] == region]\n",
    "            g = sns.barplot(x=\"Time period\", y=metric, hue=\"Algorithm\", data=m,\n",
    "                            ax=ax, saturation=0.9, palette=bar_palette)\n",
    "            g.legend_.set_visible(False)\n",
    "\n",
    "            if j > 0:\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_ylabel(None)\n",
    "            if i < 4:\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticklabels([])\n",
    "            else:    \n",
    "                for l in ax.get_xticklabels():\n",
    "                    l.set_rotation(90)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.axhline(y=0, ls=\"--\", c=\"k\")\n",
    "\n",
    "            if j == 0 and metric in y_labels:\n",
    "                ax.set_ylabel(y_labels[metric])\n",
    "\n",
    "            if metric in y_lims:\n",
    "                ax.set_ylim(y_lims[metric])\n",
    "\n",
    "    lax = f.add_subplot(gs[-1, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(*ax.get_legend_handles_labels(), ncol=6, loc=\"lower center\")\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e80d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_regional_metrics(region_metrics, precip_contribs);\n",
    "f.savefig(\"../../plots/validation/region_metrics.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_regional_metrics(region_metrics_all, precip_contribs_all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "\n",
    "results =  {\n",
    "    group: (\n",
    "        xr.concat(\n",
    "            [results_db_1_all[group], results_db_2_all[group]],\n",
    "            dim=\"samples\"\n",
    "        )\n",
    "    )\n",
    "    for group in groups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results_db_all\n",
    "del results_db_1_all\n",
    "del results_db_2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8727dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from gprof_nn.validation import NAMES, REGIONS, calculate_seasonal_cycles\n",
    "n_regions = len(REGIONS)\n",
    "\n",
    "groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "\n",
    "def plot_seasonal_cycles(\n",
    "    no_frozen=True,\n",
    "    no_snow_sfc=True,\n",
    "    no_orographic=True\n",
    "):\n",
    "    f = plt.figure(figsize=(5 * n_regions // 2, 11))\n",
    "    gs = GridSpec(4, n_regions // 2, height_ratios=[1.0, 1.0, 0.3, 0.1], hspace=0.3)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j]) for j in range(n_regions // 2)]\n",
    "        for i in range(2)\n",
    "    ])\n",
    "\n",
    "\n",
    "    for i, region in enumerate(REGIONS):\n",
    "\n",
    "        no_ocean = region != \"KWAJ\"\n",
    "\n",
    "        x, precip_strat = calculate_seasonal_cycles(results, \"reference\", region=region, precip_type=\"Stratiform\", no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_ocean=no_ocean, no_orographic=no_orographic)\n",
    "        x, precip_conv = calculate_seasonal_cycles(results, \"reference\", region=region, precip_type=\"Convective\", no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_ocean=no_ocean, no_orographic=no_orographic)\n",
    "        x, mean_ref = calculate_seasonal_cycles(results, \"reference\", region=region, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_ocean=no_ocean, no_orographic=no_orographic)\n",
    "        \n",
    "        ax = axs[i // 3, i % 3]\n",
    "\n",
    "        norm = mean_ref.mean()\n",
    "        handles_ref = [\n",
    "            ax.fill_between(x, 0, mean_ref / norm, facecolor=colors[0], label=\"MRMS (Total)\"),\n",
    "            ax.fill_between(x, 0, precip_conv / norm, facecolor=colors[2], label=\"MRMS (Convective)\"),\n",
    "            ax.fill_between(x, precip_conv / norm, (precip_conv + precip_strat) / norm, facecolor=colors[1], label=\"MRMS (Stratiform)\"),\n",
    "        ]\n",
    "\n",
    "        handles_ret = []\n",
    "\n",
    "        for j, group in enumerate(groups):\n",
    "\n",
    "            #\n",
    "            # Bias\n",
    "            #\n",
    "\n",
    "            x, mean = calculate_seasonal_cycles(results, group, region=region, no_ocean=no_ocean, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_orographic=no_orographic)\n",
    "\n",
    "            handles_ret += ax.plot(x, mean / norm, c=COLORS[group], label=NAMES[group])\n",
    "            ax.set_ylim([0, 0.5])\n",
    "            if i % 3 == 0:\n",
    "                ax.set_ylabel(r\"Surface precip. [ $\\overline{P_\\text{MRMS}}$ ]\")\n",
    "            else:\n",
    "                ax.set_ylabel(None)\n",
    "                ax.set_yticklabels([])\n",
    "            ax.set_title(f\"({chr(ord('a') + i)}) {region}\", loc=\"left\")\n",
    "            ax.set_xlim([1, 12.99])\n",
    "            ax.set_xticks(np.arange(1, 13))\n",
    "            ax.set_xticklabels(\n",
    "                [\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"]\n",
    "            )\n",
    "\n",
    "            if i // 3 == 0:\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticklabels([])\n",
    "            else:\n",
    "                ax.set_xlabel(\"Month\")\n",
    "            ax.set_xlim([1, 12])\n",
    "            ax.set_ylim([0, 3])\n",
    "\n",
    "    lax = f.add_subplot(gs[-2, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(handles=handles_ref, loc=\"lower center\", ncol=6)\n",
    "\n",
    "    lax = f.add_subplot(gs[-1, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(handles=handles_ret, loc=\"lower center\", ncol=6)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_seasonal_cycles(no_frozen=True, no_snow_sfc=True, no_orographic=True);\n",
    "f.savefig(\"../../plots/validation/seasonal_cycles.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_seasonal_cycles(no_frozen=True, no_snow_sfc=True, no_orographic=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ce950",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_seasonal_cycles(no_frozen=False, no_snow_sfc=True, no_orographic=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_seasonal_cycles(no_frozen=False, no_snow_sfc=False, no_orographic=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94788ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from gprof_nn.validation import NAMES, REGIONS, calculate_diurnal_cycles\n",
    "n_regions = len(REGIONS)\n",
    "\n",
    "def plot_diurnal_cycles(\n",
    "    no_frozen=True,\n",
    "    no_snow_sfc=True,\n",
    "    no_orographic=True\n",
    "):\n",
    "    f = plt.figure(figsize=(5 * n_regions // 2, 11))\n",
    "    gs = GridSpec(4, n_regions // 2, height_ratios=[1.0, 1.0, 0.3, 0.1], hspace=0.3)\n",
    "    axs = np.array([\n",
    "        [f.add_subplot(gs[i, j]) for j in range(n_regions // 2)]\n",
    "        for i in range(2)\n",
    "    ])\n",
    "\n",
    "    groups = [\"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "\n",
    "\n",
    "    for i, region in enumerate(REGIONS):\n",
    "        \n",
    "        #no_ocean = region != \"KWAJ\"\n",
    "        no_ocean = False\n",
    "\n",
    "        ax = axs[i // 3, i % 3]\n",
    "\n",
    "        x, precip_strat = calculate_diurnal_cycles(results, \"reference\", region=region, precip_type=\"Stratiform\", no_ocean=no_ocean, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_orographic=no_orographic)\n",
    "        x, precip_conv = calculate_diurnal_cycles(results, \"reference\", region=region, precip_type=\"Convective\", no_ocean=no_ocean, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_orographic=no_orographic)\n",
    "        x, mean_ref = calculate_diurnal_cycles(results, \"reference\", region=region, no_ocean=no_ocean, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_orographic=no_orographic)\n",
    "        norm = mean_ref.mean()\n",
    "\n",
    "        handles_ref = [\n",
    "            ax.fill_between(x, 0, mean_ref / norm, facecolor=colors[1], label=\"Ground radar (Total)\"),\n",
    "            ax.fill_between(x, 0, precip_conv / norm, facecolor=colors[2], label=\"Ground radar (Convective)\"),\n",
    "            ax.fill_between(x, precip_conv / norm, (precip_conv + precip_strat) / norm, facecolor=colors[0], label=\"Ground radar (Stratiform)\"),\n",
    "        ]\n",
    "\n",
    "        handles_ret = []\n",
    "\n",
    "        for j, group in enumerate(groups):\n",
    "\n",
    "            #\n",
    "            # Bias\n",
    "            #\n",
    "\n",
    "            x, mean = calculate_diurnal_cycles(results, group, region=region, no_ocean=no_ocean, no_frozen=no_frozen, no_snow_sfc=no_snow_sfc, no_orographic=no_orographic)\n",
    "\n",
    "            handles_ret += ax.plot(x, mean / norm, c=COLORS[group], label=NAMES[group])\n",
    "            ax.set_ylim([0, 0.5])\n",
    "            if i % 3 == 0:\n",
    "                ax.set_ylabel(r\"Surface precip. [ $\\overline{P_\\text{MRMS}}$ ]\")\n",
    "            else:\n",
    "                ax.set_ylabel(None)\n",
    "                ax.set_yticklabels([])\n",
    "            ax.set_title(f\"({chr(ord('a') + i)}) {region}\", loc=\"left\")\n",
    "            ax.set_xlim([1, 23.0])\n",
    "\n",
    "            if i // 3 == 0:\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticklabels([])\n",
    "            else:\n",
    "                ax.set_xlabel(\"Local time [$\\si{\\hour}$]\")\n",
    "            ax.set_xlim([0, 23.0])\n",
    "            ax.set_ylim([0, 2])\n",
    "\n",
    "\n",
    "    lax = f.add_subplot(gs[-2, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(handles=handles_ref, loc=\"lower center\", ncol=6)\n",
    "\n",
    "    lax = f.add_subplot(gs[-1, :])\n",
    "    lax.set_axis_off()\n",
    "    lax.legend(handles=handles_ret, loc=\"lower center\", ncol=6)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a634a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_diurnal_cycles(no_frozen=True, no_snow_sfc=True, no_orographic=True);\n",
    "f.savefig(\"../../plots/validation/diurnal_cycles.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_diurnal_cycles(no_frozen=False, no_snow_sfc=True, no_orographic=True);\n",
    "f.savefig(\"../../plots/validation/diurnal_cycles.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_diurnal_cycles(no_frozen=False, no_snow_sfc=False, no_orographic=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc3ba8",
   "metadata": {},
   "source": [
    "## Error contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = np.concatenate([\n",
    "    results_db_all[\"gprof_nn_3d\"].surface_precip.data,\n",
    "    results_db_1_all[\"gprof_nn_3d\"].surface_precip.data,\n",
    "    results_db_2_all[\"gprof_nn_3d\"].surface_precip.data,\n",
    "    results_db_3_all[\"gprof_nn_3d\"].surface_precip.data,\n",
    "], 0)\n",
    "sp_ref = np.concatenate([\n",
    "    results_db_all[\"gprof_nn_3d\"].surface_precip_ref.data,\n",
    "    results_db_1_all[\"gprof_nn_3d\"].surface_precip_ref.data,\n",
    "    results_db_2_all[\"gprof_nn_3d\"].surface_precip_ref.data,\n",
    "    results_db_3_all[\"gprof_nn_3d\"].surface_precip_ref.data,\n",
    "], 0)\n",
    "\n",
    "valid = (sp >= 0.0) * (sp_ref >= 0.0)\n",
    "sp = sp[valid]\n",
    "sp_ref = sp_ref[valid]\n",
    "\n",
    "mse = (sp - sp_ref) ** 2\n",
    "mae = np.abs(sp - sp_ref)\n",
    "\n",
    "rel_valid = sp_ref > 0.1\n",
    "smape = np.abs(sp[rel_valid] - sp_ref[rel_valid]) / (0.5 * (sp[rel_valid] + sp_ref[rel_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a43fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(np.log10(5e-2), np.log10(150), 31)\n",
    "\n",
    "y_mse = np.histogram(sp_ref, bins=bins, weights=mse)[0]\n",
    "y_mae = np.histogram(sp_ref, bins=bins, weights=mae)[0]\n",
    "y_smape = np.histogram(sp_ref[rel_valid], bins=bins, weights=smape)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5439dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "x = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "ax.bar(x, 100 * y_mse / np.sum(y_mse), width=np.diff(bins), facecolor=\"none\", edgecolor=\"C0\", label=\"MSE\", lw=1)\n",
    "ax.bar(x, 100 * y_mae / np.sum(y_mae), width=np.diff(bins), facecolor=\"none\", edgecolor=\"C1\", label=\"MAE\", lw=1)\n",
    "ax.bar(x, 100 * y_smape / np.sum(y_smape), width=np.diff(bins), facecolor=\"none\", edgecolor=\"C2\", label=\"SMAPE\", lw=1)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim([5e-2, 150])\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "ax.set_title(\"Contribution to total error\")\n",
    "ax.set_ylabel(\"Relative contribution [\\%]\")\n",
    "ax.set_xlabel(r\"$P_\\text{Reference}$ [$\\si{\\milli \\meter \\per \\hour}$]\")\n",
    "fig.savefig(\"../../plots/error_contributions.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af9949",
   "metadata": {},
   "source": [
    "## Precipitation contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa6657",
   "metadata": {},
   "source": [
    "Excluded pixels:\n",
    "- Snow-covered, non-mountain\n",
    "- MRMS snow\n",
    "- Mountain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"reference\", \"gprof_v5\", \"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\", \"combined\"]\n",
    "biases = {}\n",
    "totals = {}\n",
    "for group in groups:\n",
    "    \n",
    "    if group == \"reference\":\n",
    "        sp = results[\"gprof_v5\"].surface_precip_ref.data\n",
    "        sp_ref = results[\"gprof_v5\"].surface_precip_ref.data\n",
    "        sfc = results[\"gprof_v5\"].surface_type.data\n",
    "        mask = results[\"gprof_v5\"].mask.data\n",
    "    else:\n",
    "        sp = results[group].surface_precip.data\n",
    "        sp_ref = results[group].surface_precip_ref.data\n",
    "        sfc = results[group].surface_type.data\n",
    "        mask = results[group].mask.data\n",
    "    \n",
    "    bias = sp - sp_ref\n",
    "    \n",
    "    valid = (mask <= 100) * (sp >= 0.0) * (sp_ref >= 0.0) * (sfc > 1)\n",
    "    \n",
    "    \n",
    "    bias_g = biases.setdefault(group, {})\n",
    "    total_g = totals.setdefault(group, {})\n",
    "    \n",
    "    bias_g[\"all\"] = bias[valid].mean() / sp_ref[valid].mean() * 100\n",
    "    total_g[\"all\"] = sp[valid].sum() / sp_ref[valid].sum() * 100\n",
    "    \n",
    "    slct = valid * ~((sfc >= 8) * (sfc <= 11)) * (sfc < 17) * ~(np.isclose(mask, 3) + np.isclose(mask, 4))\n",
    "    bias_g[\"selected\"] = bias[slct].mean() / sp_ref[slct].mean() * 100.0\n",
    "    total_g[\"selected\"] = sp[slct].sum() / sp_ref[valid].sum() * 100.0\n",
    "    \n",
    "    mtn = valid * (sfc >= 17)\n",
    "    bias_g[\"mountain\"] = bias[mtn].mean() / sp_ref[mtn].mean() * 100.0\n",
    "    total_g[\"mountain\"] = sp[mtn].sum() / sp_ref[valid].sum() * 100.0\n",
    "    \n",
    "    snow = valid * (np.isclose(mask, 3) + np.isclose(mask, 4))\n",
    "    bias_g[\"mrms_snow\"] = bias[snow].mean() / sp_ref[snow].mean() * 100.0\n",
    "    total_g[\"mrms_snow\"] = sp[snow].sum() / sp_ref[valid].sum() * 100.0\n",
    "    \n",
    "    snow_sfc = valid * ((sfc >= 8) * (sfc <= 11))\n",
    "    bias_g[\"snow_sfc\"] = bias[snow_sfc].mean() / sp_ref[snow_sfc].mean() * 100.0\n",
    "    total_g[\"snow_sfc\"] = sp[snow_sfc].sum() / sp_ref[valid].sum() * 100.0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c88c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES[\"reference\"] = \"MRMS\"\n",
    "bias = []\n",
    "total = []\n",
    "precip_type = []\n",
    "source = []\n",
    "\n",
    "for group in biases.keys():\n",
    "    bias_g = biases[group]\n",
    "    total_g = totals[group]\n",
    "    for prcp_type in bias_g.keys():\n",
    "        bias.append(bias_g[prcp_type])\n",
    "        total.append(total_g[prcp_type])\n",
    "        source.append(NAMES[group])\n",
    "        precip_type.append(prcp_type)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Total precipitation\": total,\n",
    "    \"Bias\": bias,\n",
    "    \"Precipitation type\": precip_type,\n",
    "    \"Product\": source\n",
    "} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be78fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "gs = GridSpec(1, 3, width_ratios=[1.0, 1.0, 0.5], wspace=0.4)\n",
    "colors = [\"grey\"] + list(COLORS.values())\n",
    "labels = [\"All collocations\", \"Snow-free surface, \\n no mountain, \\n liquid precipitation\", \"Mountain\", \"Snow\", \"Snow-covered surface\", ]\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "g = sns.barplot(x=\"Precipitation type\", y=\"Total precipitation\", hue=\"Product\", data=data, palette=colors, saturation=1.0)\n",
    "g.legend().set_visible(False)\n",
    "ax.set_ylabel(r\"Total precipitation [\\%]\")\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.set_title(\"(a) Total precipitation\", loc=\"left\")\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "g = sns.barplot(x=\"Precipitation type\", y=\"Bias\", hue=\"Product\", data=data, palette=colors, saturation=1.0)\n",
    "g.legend().set_visible(False)\n",
    "ax.set_ylabel(\"Bias [\\%]\")\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.set_title(\"(b) Relative biases\", loc=\"left\")\n",
    "\n",
    "lax = fig.add_subplot(gs[0, 2])\n",
    "lax.legend(*ax.get_legend_handles_labels(), ncol=1, loc=\"center\")\n",
    "lax.set_axis_off()\n",
    "\n",
    "fig.savefig(\"../../plots/precip_contributions.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83925c90",
   "metadata": {},
   "source": [
    "## Explained error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gprof_nn.validation import calculate_explained_error\n",
    "\n",
    "groups = [\"gprof_v7\", \"gprof_nn_1d\", \"gprof_nn_3d\", \"gprof_nn_hr\"]\n",
    "\n",
    "\n",
    "stats_db = calculate_explained_error(results_db_ref, groups + [\"combined\"], fpa=True, no_orographic=True)\n",
    "stats_db_0 = calculate_explained_error(results_db, groups + [\"combined\"], fpa=True, no_orographic=True)\n",
    "stats_db_1 = calculate_explained_error(results_db_1, groups + [\"combined\"], fpa=True, no_orographic=True)\n",
    "stats_db_2 = calculate_explained_error(results_db_2, groups + [\"combined\"], fpa=True, no_orographic=True)\n",
    "stats_db_3 = calculate_explained_error(results_db_3, groups + [\"combined\"], fpa=True, no_orographic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b8ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_db[\"gprof_v5\"], results_db[\"gprof_nn_1d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70778fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_db[\"Time period\"] = \"Database\"\n",
    "stats_db = stats_db.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "stats_db_0[\"Time period\"] = \"2019\"\n",
    "stats_db_0 = stats_db_0.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "stats_db_1[\"Time period\"] = \"2020\"\n",
    "stats_db_1 = stats_db_1.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "stats_db_2[\"Time period\"] = \"2021\"\n",
    "stats_db_2 = stats_db_2.reset_index().rename(columns={\"index\": \"Algorithm\"})\n",
    "stats_db_3[\"Time period\"] = \"2022\"\n",
    "stats_db_3 = stats_db_3.reset_index().rename(columns={\"index\": \"Algorithm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5922b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stats = pd.concat([\n",
    "    stats_db,\n",
    "    stats_db_0,\n",
    "    stats_db_1,\n",
    "    stats_db_2,\n",
    "    stats_db_3\n",
    "])\n",
    "print(stats.pivot(index=\"Algorithm\", columns=\"Time period\").to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
